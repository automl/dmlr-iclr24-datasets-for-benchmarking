{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import openml\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.width\", 999)\n",
    "\n",
    "import tabular_data_experiments.utils.data_utils\n",
    "import tabular_data_experiments.utils.suites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = openml.datasets.list_datasets()\n",
    "all_tasks = openml.tasks.list_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_to_datasets = pd.read_csv(\"./paper_to_dataset.csv\")\n",
    "dataset_list_used = pd.read_csv(\"./dataset_list.csv\")\n",
    "dataset_list_unused = pd.read_csv(\"./dataset_list_unused.csv\")\n",
    "dataset_age = pd.read_csv(\"./dataset_age.csv\")\n",
    "for column in (\"Dataset ID\", \"Year\"):\n",
    "    dataset_age[column] = dataset_age[column].astype(\"Int64\")\n",
    "for column in (\"Dataset ID\", \"Dataset Mapping\"):\n",
    "    paper_to_datasets[column] = paper_to_datasets[column].astype(\"Int64\")\n",
    "for column in (\"Dataset ID\", ):\n",
    "    dataset_list_used[column] = dataset_list_used[column].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Key</th>\n",
       "      <th>Dataset ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Dataset Mapping</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Source</th>\n",
       "      <th>Task Type</th>\n",
       "      <th>Invalid</th>\n",
       "      <th>Note</th>\n",
       "      <th>Note to ourselves / copy to dataset sheet</th>\n",
       "      <th>reference</th>\n",
       "      <th>samples</th>\n",
       "      <th>feat</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agarwal-neurips21a</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>MIMIC2</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classification</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>requires a signed agreementr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agarwal-neurips21a</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Credit Fraud</td>\n",
       "      <td>42397</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Classification</td>\n",
       "      <td>VALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agarwal-neurips21a</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>California Housing</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regression</td>\n",
       "      <td>VALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agarwal-neurips21a</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>FICO</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regression</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not sure why they treat this as a regression d...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arik-aaai20a</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Covertype</td>\n",
       "      <td>1596</td>\n",
       "      <td>True</td>\n",
       "      <td>UCI</td>\n",
       "      <td>Classification</td>\n",
       "      <td>VALID</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://archive-beta.ics.uci.edu/dataset/31/co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Paper Key  Dataset ID        Dataset Name  Dataset Mapping  Unnamed: 4 Source       Task Type  Invalid Note          Note to ourselves / copy to dataset sheet reference samples feat  cat\n",
       "0  agarwal-neurips21a        <NA>              MIMIC2             <NA>        True    NaN  Classification  INVALID  NaN                       requires a signed agreementr       NaN     NaN  NaN  NaN\n",
       "1  agarwal-neurips21a        <NA>        Credit Fraud            42397        True    NaN  Classification    VALID  NaN                                                NaN       NaN     NaN  NaN  NaN\n",
       "2  agarwal-neurips21a        <NA>  California Housing             <NA>        True    NaN      Regression    VALID  NaN                                                NaN       NaN     NaN  NaN  NaN\n",
       "3  agarwal-neurips21a        <NA>                FICO             <NA>        True    NaN      Regression  INVALID  NaN  Not sure why they treat this as a regression d...       NaN     NaN  NaN  NaN\n",
       "4        arik-aaai20a        <NA>           Covertype             1596        True    UCI  Classification    VALID  NaN  https://archive-beta.ics.uci.edu/dataset/31/co...       NaN     NaN  NaN  NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_to_datasets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "suite_names = paper_to_datasets.loc[:, \"Paper Key\"].unique()\n",
    "assert len(suite_names) == 31, len(suite_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_name(dataset_id, dataset_name):\n",
    "    if not pd.isna(dataset_name):\n",
    "        return dataset_name.lower()\n",
    "    else:\n",
    "        return all_datasets[dataset_id][\"name\"].lower()\n",
    "\n",
    "dataset_counts = {}\n",
    "openml_suite_datasets = set()\n",
    "dataset_names = {}\n",
    "regression_counts = {}\n",
    "for _, row in paper_to_datasets.iterrows():\n",
    "    if row[\"Task Type\"] == \"Regression\":\n",
    "        dataset_name = row[\"Dataset Name\"]\n",
    "        if dataset_name not in regression_counts:\n",
    "            regression_counts[dataset_name] = 1\n",
    "        else:\n",
    "            regression_counts[dataset_name] += 1\n",
    "    elif row[\"Paper Key\"] in (\"gijsbers-arxiv22a\", \"bischl-neuripsdbt21a\"):\n",
    "        openml_suite_datasets.add(row[\"Dataset ID\"])\n",
    "    elif row[\"Invalid\"] == \"INVALID\":\n",
    "        name = row[\"Dataset Name\"]\n",
    "        if name in dataset_counts:\n",
    "            dataset_counts[name] += 1\n",
    "        else:\n",
    "            dataset_counts[name] = 1\n",
    "            dataset_names[name] = set([name])\n",
    "    else:\n",
    "        dataset_id = row[\"Dataset ID\"]\n",
    "        dataset_mapping = row[\"Dataset Mapping\"]\n",
    "        if pd.isna(dataset_id) and pd.isna(dataset_mapping):\n",
    "            raise ValueError(\"Both dataset ID fields are empty\", row)\n",
    "        elif not pd.isna(dataset_id) and not pd.isna(dataset_mapping):\n",
    "            raise ValueError(\"Both dataset ID fields are populated\", row)\n",
    "        elif pd.isna(dataset_id):\n",
    "            did = int(dataset_mapping)\n",
    "        else:\n",
    "            did = int(dataset_id)\n",
    "        name = lookup_name(did, row[\"Dataset Name\"])\n",
    "        if did not in dataset_counts:\n",
    "            dataset_counts[did] = 1\n",
    "            dataset_names[did] = set([name])\n",
    "        else:\n",
    "            dataset_counts[did] += 1\n",
    "            dataset_names[did].add(name)\n",
    "\n",
    "dataset_stats = pd.DataFrame([dataset_counts, dataset_names]).transpose()\n",
    "dataset_stats.columns = [\"Count\", \"Name\"]\n",
    "dataset_stats[\"available\"] = {idx: isinstance(idx, int) for idx in dataset_stats.index}\n",
    "dataset_stats[\"Creation\"] = {idx: dataset_age[dataset_age[\"Dataset ID\"] == idx][\"Year\"].tolist() if isinstance(idx, int) else [] for idx in dataset_stats.index}\n",
    "dataset_stats[\"Creation\"] = dataset_stats[\"Creation\"].apply(lambda entry: entry[0] if len(entry) > 0 else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets used according to Google Doc sheet 'Dataset list': 187\n",
      "Number of datasets that are only in the CC18 and AutoML benchmark 20\n",
      "Number of Classification datasets (excluding CC18 and AMLB) 191\n",
      "Number of available Classification Datasets used 167\n",
      "Number of unavailable datasets 24\n",
      "Number of available and unavailable and OpenML datasets 211\n",
      "Number of Regression Datasets 54\n"
     ]
    }
   ],
   "source": [
    "print(\"Datasets used according to Google Doc sheet 'Dataset list':\", len(set(dataset_list_used[\"Dataset ID\"].to_list())))\n",
    "# print(dataset_list_unused.index)\n",
    "dataset_ids_used = [idx for idx in dataset_stats.index if isinstance(idx, int)]\n",
    "if len(set(dataset_ids_used) - set(dataset_list_used[\"Dataset ID\"].to_list())) != 0:\n",
    "    print(\"Datasets that are missing in 'Dataset list':\", set(dataset_ids_used) - set(dataset_list_used[\"Dataset ID\"].to_list()))\n",
    "\n",
    "if len(set(dataset_list_used[\"Dataset ID\"].to_list()) - set(dataset_ids_used) - set(openml_suite_datasets)) != 0:\n",
    "    print(\"Datasets that are missing in 'Paper to Dataset':\", set(dataset_list_used[\"Dataset ID\"].to_list()) - set(dataset_ids_used) - set(openml_suite_datasets))\n",
    "\n",
    "if len(openml_suite_datasets - set(dataset_list_used[\"Dataset ID\"].to_list())) != 0:\n",
    "       print(\"Datasets from the CC18 and the AutoML benchmark that are not in the datasets list\", set(openml_suite_datasets) - set(dataset_list_used[\"Dataset ID\"].to_list()))\n",
    "\n",
    "if len(dataset_list_used) != len(dataset_age):\n",
    "     print(\n",
    "        \"Datasets in dataset list and dataset age list are disjoint\",\n",
    "        \"dataset age list misses\", set(dataset_list_used[\"Dataset ID\"]) - set(dataset_age[\"Dataset ID\"]),\n",
    "        \"dataset list misses\", set(dataset_age[\"Dataset ID\"]) - set(dataset_list_used[\"Dataset ID\"])\n",
    "    )\n",
    "   \n",
    "only_openml = openml_suite_datasets - set(dataset_stats[dataset_stats[\"available\"]].index)\n",
    "print(\"Number of datasets that are only in the CC18 and AutoML benchmark\", len(only_openml))\n",
    "print(\"Number of Classification datasets (excluding CC18 and AMLB)\", len(dataset_stats))\n",
    "print(\"Number of available Classification Datasets used\", dataset_stats[\"available\"].sum())\n",
    "print(\"Number of unavailable datasets\", (~dataset_stats[\"available\"]).sum())\n",
    "print(\"Number of available and unavailable and OpenML datasets\", len(dataset_stats) + len(only_openml))\n",
    "\n",
    "if (~dataset_stats[\"available\"]).sum() != len(dataset_list_unused):\n",
    "    print(\"Number of unavailable datasets is different for different lists\", (~dataset_stats[\"available\"]).sum(), len(dataset_list_unused))\n",
    "\n",
    "# NOTE: we do not count invalid regression datasets yet!\n",
    "if set([list(entry)[0] for entry in dataset_stats[~dataset_stats[\"available\"]][\"Name\"]]) != set(dataset_list_unused[\"Dataset Name\"]):\n",
    "    dataset_names_unavailable = set([list(entry)[0] for entry in dataset_stats[~dataset_stats[\"available\"]][\"Name\"]])\n",
    "    print(\n",
    "       \"Unavailable datasets are different in different tables. The following ones are not in both Tables:\", \n",
    "       dataset_names_unavailable.symmetric_difference(set(dataset_list_unused[\"Dataset Name\"]))\n",
    "    )\n",
    "\n",
    "print(\"Number of Regression Datasets\", len(regression_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>available</th>\n",
       "      <th>Creation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>12</td>\n",
       "      <td>{covertype}</td>\n",
       "      <td>True</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>10</td>\n",
       "      <td>{adult income, adult roc, adult}</td>\n",
       "      <td>True</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45575</th>\n",
       "      <td>6</td>\n",
       "      <td>{epsilon}</td>\n",
       "      <td>True</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45570</th>\n",
       "      <td>6</td>\n",
       "      <td>{higgs}</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4538</th>\n",
       "      <td>5</td>\n",
       "      <td>{gesture phase, gesture phase prediction, gest...</td>\n",
       "      <td>True</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Count                                               Name  available  Creation\n",
       "1596     12                                        {covertype}       True      1998\n",
       "1590     10                   {adult income, adult roc, adult}       True      1996\n",
       "45575     6                                          {epsilon}       True      2008\n",
       "45570     6                                            {higgs}       True      2014\n",
       "4538      5  {gesture phase, gesture phase prediction, gest...       True      2014"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_stats = dataset_stats.sort_values(by=[\"Count\"], ascending=False)\n",
    "sorted_stats[\"Creation\"] = sorted_stats[\"Creation\"].astype(\"Int64\")\n",
    "sorted_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|        |   Count | Name                                                                               | available   | Creation   |\n",
      "|:-------|--------:|:-----------------------------------------------------------------------------------|:------------|:-----------|\n",
      "| 1596   |      12 | {'covertype'}                                                                      | True        | 1998       |\n",
      "| 1590   |      10 | {'adult income', 'adult roc', 'adult'}                                             | True        | 1996       |\n",
      "| 45575  |       6 | {'epsilon'}                                                                        | True        | 2008       |\n",
      "| 45570  |       6 | {'higgs'}                                                                          | True        | 2014       |\n",
      "| 4538   |       5 | {'gesture phase', 'gesture phase prediction', 'gesturephasesegmentationprocessed'} | True        | 2014       |\n",
      "| 45062  |       5 | {'shrutime', 'churn modelling'}                                                    | True        | 2019       |\n",
      "| 23512  |       5 | {'higgs small'}                                                                    | True        | 2014       |\n",
      "| 31     |       5 | {'german credit', 'credit-g'}                                                      | True        | 1994       |\n",
      "| 1464   |       4 | {'blood-transfusion-service-center', 'blood-transfusion'}                          | True        | 2008       |\n",
      "| 42397  |       4 | {'credit', 'c.c.fraudd', 'credit fraud'}                                           | True        | 2015       |\n",
      "| 1494   |       4 | {'qsar-biodeg'}                                                                    | True        | 2013       |\n",
      "| 37     |       4 | {'diabetes'}                                                                       | True        | 1988       |\n",
      "| Click  |       4 | {'Click'}                                                                          | False       | <NA>       |\n",
      "| 45554  |       4 | {'fico'}                                                                           | True        | 2018       |\n",
      "| 40975  |       4 | {'car'}                                                                            | True        | 1988       |\n",
      "| 1461   |       3 | {'bank-marketing'}                                                                 | True        | 2011       |\n",
      "| MIMIC2 |       3 | {'MIMIC2'}                                                                         | False       | <NA>       |\n",
      "| 6332   |       3 | {'cylinder-bands'}                                                                 | True        | 1994       |\n",
      "| 54     |       3 | {'vehicle'}                                                                        | True        | 1987       |\n",
      "| 41169  |       3 | {'helena'}                                                                         | True        | 2010       |\n"
     ]
    }
   ],
   "source": [
    "print(sorted_stats.iloc[:20].to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrr}\n",
      "\\toprule\n",
      " & Count & Name & available & Creation \\\\\n",
      "\\midrule\n",
      "1596 & 12 & {'covertype'} & True & 1998 \\\\\n",
      "1590 & 10 & {'adult income', 'adult roc', 'adult'} & True & 1996 \\\\\n",
      "45575 & 6 & {'epsilon'} & True & 2008 \\\\\n",
      "45570 & 6 & {'higgs'} & True & 2014 \\\\\n",
      "4538 & 5 & {'gesture phase', 'gesture phase prediction', 'gesturephasesegmentationprocessed'} & True & 2014 \\\\\n",
      "45062 & 5 & {'shrutime', 'churn modelling'} & True & 2019 \\\\\n",
      "23512 & 5 & {'higgs small'} & True & 2014 \\\\\n",
      "31 & 5 & {'german credit', 'credit-g'} & True & 1994 \\\\\n",
      "1464 & 4 & {'blood-transfusion-service-center', 'blood-transfusion'} & True & 2008 \\\\\n",
      "42397 & 4 & {'credit', 'c.c.fraudd', 'credit fraud'} & True & 2015 \\\\\n",
      "1494 & 4 & {'qsar-biodeg'} & True & 2013 \\\\\n",
      "37 & 4 & {'diabetes'} & True & 1988 \\\\\n",
      "Click & 4 & {'Click'} & False & NaN \\\\\n",
      "45554 & 4 & {'fico'} & True & 2018 \\\\\n",
      "40975 & 4 & {'car'} & True & 1988 \\\\\n",
      "1461 & 3 & {'bank-marketing'} & True & 2011 \\\\\n",
      "MIMIC2 & 3 & {'MIMIC2'} & False & NaN \\\\\n",
      "6332 & 3 & {'cylinder-bands'} & True & 1994 \\\\\n",
      "54 & 3 & {'vehicle'} & True & 1987 \\\\\n",
      "41169 & 3 & {'helena'} & True & 2010 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sorted_stats.iloc[:20].to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllr}\n",
      "\\toprule\n",
      " & Count & Name & Creation \\\\\n",
      "\\midrule\n",
      "\\href{https://openml.org/d/2}{2} & 1 & anneal & 1990 \\\\\n",
      "\\href{https://openml.org/d/3}{3} & 2 & kr-vs-kp & 1983 \\\\\n",
      "\\href{https://openml.org/d/5}{5} & 1 & arrhythmia & 1998 \\\\\n",
      "\\href{https://openml.org/d/6}{6} & 1 & letter & 1991 \\\\\n",
      "\\href{https://openml.org/d/11}{11} & 2 & balance-scale & 1976 \\\\\n",
      "\\href{https://openml.org/d/12}{12} & 2 & mfeat-factors & 1998 \\\\\n",
      "\\href{https://openml.org/d/13}{13} & 3 & breast-cancer & 1988 \\\\\n",
      "\\href{https://openml.org/d/14}{14} & 2 & mfeat-fourier & 1998 \\\\\n",
      "\\href{https://openml.org/d/15}{15} & 2 & breast-w & 1990 \\\\\n",
      "\\href{https://openml.org/d/16}{16} & 2 & mfeat-karhunen & 1998 \\\\\n",
      "\\href{https://openml.org/d/18}{18} & 2 & mfeat-morphological & 1998 \\\\\n",
      "\\href{https://openml.org/d/22}{22} & 2 & mfeat-zernike & 1998 \\\\\n",
      "\\href{https://openml.org/d/23}{23} & 2 & cmc & 1987 \\\\\n",
      "\\href{https://openml.org/d/25}{25} & 1 & horse-colic  & 1989 \\\\\n",
      "\\href{https://openml.org/d/28}{28} & 2 & optdigits & 1995 \\\\\n",
      "\\href{https://openml.org/d/29}{29} & 3 & credit-approval & 1987 \\\\\n",
      "\\href{https://openml.org/d/31}{31} & 5 & german credit & 1994 \\\\\n",
      "\\href{https://openml.org/d/32}{32} & 1 & pendigits & 1994 \\\\\n",
      "\\href{https://openml.org/d/37}{37} & 4 & diabetes & 1988 \\\\\n",
      "\\href{https://openml.org/d/38}{38} & 2 & sick & 1986 \\\\\n",
      "\\href{https://openml.org/d/40}{40} & 1 & conn-bench-sonar-mines-rocks  & 1988 \\\\\n",
      "\\href{https://openml.org/d/41}{41} & 1 & glass & 1987 \\\\\n",
      "\\href{https://openml.org/d/43}{43} & 1 & haberman-survival & 1976 \\\\\n",
      "\\href{https://openml.org/d/44}{44} & 3 & spambase & 1999 \\\\\n",
      "\\href{https://openml.org/d/46}{46} & 1 & splice & 1991 \\\\\n",
      "\\href{https://openml.org/d/49}{49} & 1 & heart-cleveland & 1988 \\\\\n",
      "\\href{https://openml.org/d/50}{50} & 2 & tic-tac-toe & 1990 \\\\\n",
      "\\href{https://openml.org/d/53}{53} & 1 & statlog-heart & 1988 \\\\\n",
      "\\href{https://openml.org/d/54}{54} & 3 & vehicle & 1987 \\\\\n",
      "\\href{https://openml.org/d/56}{56} & 1 & congressional-voting & 1984 \\\\\n",
      "\\href{https://openml.org/d/61}{61} & 2 & iris & 1936 \\\\\n",
      "\\href{https://openml.org/d/151}{151} & 1 & electricity & 1999 \\\\\n",
      "\\href{https://openml.org/d/171}{171} & 1 & primary-tumor & 1988 \\\\\n",
      "\\href{https://openml.org/d/182}{182} & 1 & satimage & 1993 \\\\\n",
      "\\href{https://openml.org/d/187}{187} & 2 & wine & 1998 \\\\\n",
      "\\href{https://openml.org/d/188}{188} & 3 & eucalyptus & 1992 \\\\\n",
      "\\href{https://openml.org/d/300}{300} & 1 & isolet & 1991 \\\\\n",
      "\\href{https://openml.org/d/307}{307} & 1 & vowel & 1987 \\\\\n",
      "\\href{https://openml.org/d/458}{458} & 2 & analcatdata\\_auth... & 2003 \\\\\n",
      "\\href{https://openml.org/d/469}{469} & 2 & analcatdata\\_dmft & 2003 \\\\\n",
      "\\href{https://openml.org/d/554}{554} & 1 & mnist & 1998 \\\\\n",
      "\\href{https://openml.org/d/1017}{1017} & 1 & arrhythmia & 1998 \\\\\n",
      "\\href{https://openml.org/d/1044}{1044} & 1 & eye movement & 2005 \\\\\n",
      "\\href{https://openml.org/d/1049}{1049} & 2 & pc4 & 2004 \\\\\n",
      "\\href{https://openml.org/d/1050}{1050} & 2 & pc3 & 2004 \\\\\n",
      "\\href{https://openml.org/d/1053}{1053} & 1 & jm1 & 2004 \\\\\n",
      "\\href{https://openml.org/d/1063}{1063} & 2 & kc2 & 2004 \\\\\n",
      "\\href{https://openml.org/d/1067}{1067} & 2 & kc1 & 2004 \\\\\n",
      "\\href{https://openml.org/d/1068}{1068} & 2 & pc1 & 2004 \\\\\n",
      "\\href{https://openml.org/d/1111}{1111} & 1 & kddcup09-appetency & 2009 \\\\\n",
      "\\href{https://openml.org/d/1119}{1119} & 1 & adult & 1996 \\\\\n",
      "\\href{https://openml.org/d/1219}{1219} & 1 & click prediction & 2012 \\\\\n",
      "\\href{https://openml.org/d/1430}{1430} & 1 & a9a & 1998 \\\\\n",
      "\\href{https://openml.org/d/1461}{1461} & 3 & bank-marketing & 2011 \\\\\n",
      "\\href{https://openml.org/d/1462}{1462} & 2 & banknote-authentication & 2013 \\\\\n",
      "\\href{https://openml.org/d/1464}{1464} & 4 & blood-transfusion-service-center & 2008 \\\\\n",
      "\\href{https://openml.org/d/1468}{1468} & 2 & cnae-9 & 2009 \\\\\n",
      "\\href{https://openml.org/d/1475}{1475} & 1 & first-order-theorem-proving & 2013 \\\\\n",
      "\\href{https://openml.org/d/1477}{1477} & 1 & gas concentration & 2012 \\\\\n",
      "\\href{https://openml.org/d/1478}{1478} & 1 & har & 2012 \\\\\n",
      "\\href{https://openml.org/d/1480}{1480} & 2 & ilpd & 2011 \\\\\n",
      "\\href{https://openml.org/d/1483}{1483} & 1 & ldpa & 2010 \\\\\n",
      "\\href{https://openml.org/d/1485}{1485} & 1 & madelon & 2003 \\\\\n",
      "\\href{https://openml.org/d/1486}{1486} & 2 & nomao & 2008 \\\\\n",
      "\\href{https://openml.org/d/1487}{1487} & 2 & ozone-level-8hr & 2005 \\\\\n",
      "\\href{https://openml.org/d/1489}{1489} & 2 & phoneme & 1993 \\\\\n",
      "\\href{https://openml.org/d/1494}{1494} & 4 & qsar-biodeg & 2013 \\\\\n",
      "\\href{https://openml.org/d/1497}{1497} & 1 & wall-robot-navigation & 2009 \\\\\n",
      "\\href{https://openml.org/d/1501}{1501} & 1 & semeion & 1994 \\\\\n",
      "\\href{https://openml.org/d/1502}{1502} & 1 & skin-segmentation & 2009 \\\\\n",
      "\\href{https://openml.org/d/1509}{1509} & 1 & walking-activity & 2012 \\\\\n",
      "\\href{https://openml.org/d/1510}{1510} & 2 & wdbc & 1992 \\\\\n",
      "\\href{https://openml.org/d/1523}{1523} & 1 & vertebral-column3 & 2005 \\\\\n",
      "\\href{https://openml.org/d/1524}{1524} & 1 & vertebral-column2 & 2005 \\\\\n",
      "\\href{https://openml.org/d/1567}{1567} & 2 & poker & 2002 \\\\\n",
      "\\href{https://openml.org/d/1590}{1590} & 10 & adult income & 1996 \\\\\n",
      "\\href{https://openml.org/d/1596}{1596} & 12 & covertype & 1998 \\\\\n",
      "\\href{https://openml.org/d/4134}{4134} & 2 & bioresponse & 2011 \\\\\n",
      "\\href{https://openml.org/d/4534}{4534} & 1 & phishingwebsites & 2012 \\\\\n",
      "\\href{https://openml.org/d/4535}{4535} & 1 & income & 1995 \\\\\n",
      "\\href{https://openml.org/d/4538}{4538} & 5 & gesture phase & 2014 \\\\\n",
      "\\href{https://openml.org/d/4541}{4541} & 1 & diabetes 130us & 2014 \\\\\n",
      "\\href{https://openml.org/d/6332}{6332} & 3 & cylinder-bands & 1994 \\\\\n",
      "\\href{https://openml.org/d/23381}{23381} & 2 & dresses-sales & 2014 \\\\\n",
      "\\href{https://openml.org/d/23512}{23512} & 5 & higgs small & 2014 \\\\\n",
      "\\href{https://openml.org/d/23517}{23517} & 2 & numerai28.6 & 2016 \\\\\n",
      "\\href{https://openml.org/d/40499}{40499} & 1 & texture & 1966 \\\\\n",
      "\\href{https://openml.org/d/40664}{40664} & 1 & car-evaluation & 1988 \\\\\n",
      "\\href{https://openml.org/d/40668}{40668} & 2 & connect-4 & 1995 \\\\\n",
      "\\href{https://openml.org/d/40670}{40670} & 1 & dna & 1991 \\\\\n",
      "\\href{https://openml.org/d/40685}{40685} & 2 & shuttle & 1994 \\\\\n",
      "\\href{https://openml.org/d/40687}{40687} & 1 & solar-flare & 1989 \\\\\n",
      "\\href{https://openml.org/d/40701}{40701} & 1 & churn & 2012 \\\\\n",
      "\\href{https://openml.org/d/40923}{40923} & 2 & devnagari-script & 2015 \\\\\n",
      "\\href{https://openml.org/d/40966}{40966} & 2 & miceprotein & 2015 \\\\\n",
      "\\href{https://openml.org/d/40975}{40975} & 4 & car & 1988 \\\\\n",
      "\\href{https://openml.org/d/40978}{40978} & 1 & internet-advertisements & 1998 \\\\\n",
      "\\href{https://openml.org/d/40979}{40979} & 1 & mfeat-pixel & 1998 \\\\\n",
      "\\href{https://openml.org/d/40981}{40981} & 1 & australian & 1987 \\\\\n",
      "\\href{https://openml.org/d/40982}{40982} & 2 & steel-plates-fault & 1998 \\\\\n",
      "\\href{https://openml.org/d/40983}{40983} & 2 & wilt & 2013 \\\\\n",
      "\\href{https://openml.org/d/40984}{40984} & 2 & segment & 1990 \\\\\n",
      "\\href{https://openml.org/d/40994}{40994} & 2 & climate-model-simulation-crashes & 2013 \\\\\n",
      "\\href{https://openml.org/d/40996}{40996} & 1 & fashion-mnist & 2017 \\\\\n",
      "\\href{https://openml.org/d/41027}{41027} & 2 & jungle-chess-2pc & 2014 \\\\\n",
      "\\href{https://openml.org/d/41138}{41138} & 1 & apsfailure & 2016 \\\\\n",
      "\\href{https://openml.org/d/41142}{41142} & 1 & christine & 2006 \\\\\n",
      "\\href{https://openml.org/d/41143}{41143} & 2 & jasmine & 2009 \\\\\n",
      "\\href{https://openml.org/d/41145}{41145} & 1 & philippine & 2009 \\\\\n",
      "\\href{https://openml.org/d/41146}{41146} & 2 & sylvine & 1998 \\\\\n",
      "\\href{https://openml.org/d/41147}{41147} & 1 & albert & 2014 \\\\\n",
      "\\href{https://openml.org/d/41150}{41150} & 2 & miniboone & 2005 \\\\\n",
      "\\href{https://openml.org/d/41162}{41162} & 1 & kick & 2012 \\\\\n",
      "\\href{https://openml.org/d/41163}{41163} & 1 & dilbert & 2014 \\\\\n",
      "\\href{https://openml.org/d/41164}{41164} & 2 & fabert & 2013 \\\\\n",
      "\\href{https://openml.org/d/41166}{41166} & 3 & volkert & 2006 \\\\\n",
      "\\href{https://openml.org/d/41167}{41167} & 1 & dionis & 2014 \\\\\n",
      "\\href{https://openml.org/d/41168}{41168} & 3 & jannis & 2010 \\\\\n",
      "\\href{https://openml.org/d/41169}{41169} & 3 & helena & 2010 \\\\\n",
      "\\href{https://openml.org/d/42193}{42193} & 1 & compas & 2016 \\\\\n",
      "\\href{https://openml.org/d/42396}{42396} & 2 & aloi & 2014 \\\\\n",
      "\\href{https://openml.org/d/42397}{42397} & 4 & credit & 2015 \\\\\n",
      "\\href{https://openml.org/d/42477}{42477} & 1 & default & 2009 \\\\\n",
      "\\href{https://openml.org/d/42733}{42733} & 1 & click prediction small & 2012 \\\\\n",
      "\\href{https://openml.org/d/42734}{42734} & 1 & okcupid-stem & 2011 \\\\\n",
      "\\href{https://openml.org/d/44089}{44089} & 1 & jannis & 2011 \\\\\n",
      "\\href{https://openml.org/d/44120}{44120} & 1 & electricity & 1999 \\\\\n",
      "\\href{https://openml.org/d/44121}{44121} & 1 & covertype & 1998 \\\\\n",
      "\\href{https://openml.org/d/44122}{44122} & 1 & pol & 1995 \\\\\n",
      "\\href{https://openml.org/d/44123}{44123} & 1 & house\\_16h & 1990 \\\\\n",
      "\\href{https://openml.org/d/44125}{44125} & 1 & magicaltelescope & 2004 \\\\\n",
      "\\href{https://openml.org/d/44126}{44126} & 1 & bank-marketing & 2011 \\\\\n",
      "\\href{https://openml.org/d/44129}{44129} & 1 & default\\_of-credit-card-clients & 2014 \\\\\n",
      "\\href{https://openml.org/d/44130}{44130} & 1 & higgs small & 2005 \\\\\n",
      "\\href{https://openml.org/d/44156}{44156} & 1 & electricity & 1999 \\\\\n",
      "\\href{https://openml.org/d/44157}{44157} & 1 & eye movement & 2005 \\\\\n",
      "\\href{https://openml.org/d/44159}{44159} & 1 & covertype & 1998 \\\\\n",
      "\\href{https://openml.org/d/45019}{45019} & 1 & bioresponse & 2011 \\\\\n",
      "\\href{https://openml.org/d/45020}{45020} & 1 & miniboone & 2009 \\\\\n",
      "\\href{https://openml.org/d/45021}{45021} & 1 & diabetes130us & 2010 \\\\\n",
      "\\href{https://openml.org/d/45022}{45022} & 1 & eye movement & 2008 \\\\\n",
      "\\href{https://openml.org/d/45028}{45028} & 1 & credit & 1997 \\\\\n",
      "\\href{https://openml.org/d/45035}{45035} & 1 & albert & 2014 \\\\\n",
      "\\href{https://openml.org/d/45036}{45036} & 1 & default\\_of-credit-card-clients & 2009 \\\\\n",
      "\\href{https://openml.org/d/45038}{45038} & 1 & road-safety & 2015 \\\\\n",
      "\\href{https://openml.org/d/45039}{45039} & 1 & compas-two-years & 2016 \\\\\n",
      "\\href{https://openml.org/d/45062}{45062} & 5 & shrutime & 2019 \\\\\n",
      "\\href{https://openml.org/d/45069}{45069} & 1 & diabetes & 2008 \\\\\n",
      "\\href{https://openml.org/d/45545}{45545} & 1 & travel customers & 2021 \\\\\n",
      "\\href{https://openml.org/d/45547}{45547} & 2 & cardio & 1999 \\\\\n",
      "\\href{https://openml.org/d/45548}{45548} & 2 & otto group product classification & 2015 \\\\\n",
      "\\href{https://openml.org/d/45551}{45551} & 2 & higgs kaggle & 2014 \\\\\n",
      "\\href{https://openml.org/d/45554}{45554} & 4 & fico & 2018 \\\\\n",
      "\\href{https://openml.org/d/45556}{45556} & 1 & click & 2012 \\\\\n",
      "\\href{https://openml.org/d/45557}{45557} & 1 & mammographic & 2006 \\\\\n",
      "\\href{https://openml.org/d/45558}{45558} & 1 & htru2 & 2010 \\\\\n",
      "\\href{https://openml.org/d/45559}{45559} & 1 & insurance\\_co & 2000 \\\\\n",
      "\\href{https://openml.org/d/45560}{45560} & 1 & online\\_shoppers & 2018 \\\\\n",
      "\\href{https://openml.org/d/45562}{45562} & 1 & seismicbumps & 2010 \\\\\n",
      "\\href{https://openml.org/d/45563}{45563} & 1 & dota2games & 2016 \\\\\n",
      "\\href{https://openml.org/d/45565}{45565} & 1 & 1995\\_income & 1996 \\\\\n",
      "\\href{https://openml.org/d/45566}{45566} & 1 & santander customer transaction prediction5 & 2019 \\\\\n",
      "\\href{https://openml.org/d/45567}{45567} & 1 & hcdr\\_main & 2018 \\\\\n",
      "\\href{https://openml.org/d/45568}{45568} & 3 & telco-customer-churn & 2018 \\\\\n",
      "\\href{https://openml.org/d/45570}{45570} & 6 & higgs & 2014 \\\\\n",
      "\\href{https://openml.org/d/45575}{45575} & 6 & epsilon & 2008 \\\\\n",
      "\\href{https://openml.org/d/45579}{45579} & 1 & microsoft & 2013 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_stats_all = sorted_stats.copy().loc[sorted_stats[\"available\"]].sort_index()\n",
    "sorted_stats_all.index = [\"\\href{https://openml.org/d/%d}{%d}\" % (dataset_id, dataset_id) for dataset_id in sorted_stats_all.index]\n",
    "sorted_stats_all[\"Name\"] = [list(name)[0] for name in sorted_stats_all[\"Name\"]]\n",
    "print(\n",
    "    sorted_stats_all.\n",
    "    drop(\"available\", axis=1).\n",
    "    to_latex().\n",
    "    replace(\"_\", \"\\_\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 2 687 (covertype (1596), higgs (45570)), (covertype (1596), epsilon (45575)), (adult (1590), higgs (23512))\n",
      "2 3 38 (covertype (1596), higgs (45570)), (covertype (1596), epsilon (45575)), (adult (1590), higgs (23512))\n",
      "2 4 8 (covertype (1596), higgs (45570)), (covertype (1596), epsilon (45575)), (adult (1590), higgs (23512))\n",
      "2 5 3 (covertype (1596), higgs (45570)), (covertype (1596), epsilon (45575)), (adult (1590), higgs (23512))\n",
      "3 2 4925 (blood-transfusion-service-center (1464), credit-approval (29), cylinder-bands (6332)), (blood-transfusion-service-center (1464), credit-g (31), vehicle (54)), (credit-g (31), car (40975), vehicle (54)), (qsar-biodeg (1494), eucalyptus (188), credit-g (31)), (eucalyptus (188), credit-g (31), car (40975)), (blood-transfusion-service-center (1464), credit-g (31), car (40975)), (qsar-biodeg (1494), credit-g (31), car (40975)), (adult (1590), credit-g (31), car (40975)), (blood-transfusion-service-center (1464), car (40975), vehicle (54)), (qsar-biodeg (1494), eucalyptus (188), car (40975)), (covertype (1596), fico-heloc-cleaned (45554), higgs (45570)), (covertype (1596), epsilon (45575), Click), (higgs (45570), epsilon (45575), Click), (adult (1590), covertype (1596), higgs (23512)), (adult (1590), shrutime (45062), gesturephasesegmentationprocessed (4538)), (higgs (23512), shrutime (45062), gesturephasesegmentationprocessed (4538)), (covertype (1596), shrutime (45062), gesturephasesegmentationprocessed (4538)), (adult (1590), higgs (23512), gesturephasesegmentationprocessed (4538)), (adult (1590), higgs (23512), shrutime (45062))\n",
      "3 3 19 (blood-transfusion-service-center (1464), credit-approval (29), cylinder-bands (6332)), (blood-transfusion-service-center (1464), credit-g (31), vehicle (54)), (credit-g (31), car (40975), vehicle (54)), (qsar-biodeg (1494), eucalyptus (188), credit-g (31)), (eucalyptus (188), credit-g (31), car (40975)), (blood-transfusion-service-center (1464), credit-g (31), car (40975)), (qsar-biodeg (1494), credit-g (31), car (40975)), (adult (1590), credit-g (31), car (40975)), (blood-transfusion-service-center (1464), car (40975), vehicle (54)), (qsar-biodeg (1494), eucalyptus (188), car (40975)), (covertype (1596), fico-heloc-cleaned (45554), higgs (45570)), (covertype (1596), epsilon (45575), Click), (higgs (45570), epsilon (45575), Click), (adult (1590), covertype (1596), higgs (23512)), (adult (1590), shrutime (45062), gesturephasesegmentationprocessed (4538)), (higgs (23512), shrutime (45062), gesturephasesegmentationprocessed (4538)), (covertype (1596), shrutime (45062), gesturephasesegmentationprocessed (4538)), (adult (1590), higgs (23512), gesturephasesegmentationprocessed (4538)), (adult (1590), higgs (23512), shrutime (45062))\n",
      "4 2 29975 (blood-transfusion-service-center (1464), credit-g (31), car (40975), vehicle (54)), (qsar-biodeg (1494), eucalyptus (188), credit-g (31), car (40975)), (adult (1590), higgs (23512), shrutime (45062), gesturephasesegmentationprocessed (4538))\n",
      "4 3 3 (blood-transfusion-service-center (1464), credit-g (31), car (40975), vehicle (54)), (qsar-biodeg (1494), eucalyptus (188), credit-g (31), car (40975)), (adult (1590), higgs (23512), shrutime (45062), gesturephasesegmentationprocessed (4538))\n",
      "5 2 148825 (kc1 (1067), mfeat-factors (12), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), bank-marketing (1461), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), blood-transfusion-service-center (1464), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), cnae-9 (1468), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), nomao (1486), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), phoneme (1489), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), adult (1590), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), numerai28.6 (23517), kr-vs-kp (3), credit-g (31), vehicle (54)), (mfeat-factors (12), kr-vs-kp (3), credit-g (31), connect-4 (40668), vehicle (54)), (mfeat-factors (12), kr-vs-kp (3), credit-g (31), devnagari-script (40923), vehicle (54)), (mfeat-factors (12), kr-vs-kp (3), credit-g (31), car (40975), vehicle (54)), (mfeat-factors (12), kr-vs-kp (3), credit-g (31), segment (40984), vehicle (54)), (mfeat-factors (12), kr-vs-kp (3), credit-g (31), jungle_chess_2pcs_raw_endgame_complete (41027), vehicle (54)), (kc1 (1067), mfeat-factors (12), bank-marketing (1461), kr-vs-kp (3), credit-g (31)), (kc1 (1067), mfeat-factors (12), blood-transfusion-service-center (1464), kr-vs-kp (3), credit-g (31)), (kc1 (1067), mfeat-factors (12), cnae-9 (1468), kr-vs-kp (3), credit-g (31)), (kc1 (1067), mfeat-factors (12), nomao (1486), kr-vs-kp (3), credit-g (31)), (kc1 (1067), mfeat-factors (12), phoneme (1489), kr-vs-kp (3), credit-g (31)), (kc1 (1067), mfeat-factors (12), adult (1590), kr-vs-kp (3), credit-g (31)), (kc1 (1067), mfeat-factors (12), numerai28.6 (23517), kr-vs-kp (3), credit-g (31))\n",
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      " & 2 & 3 & 4 & 5 \\\\\n",
      "\\midrule\n",
      "2 & 687 & 4925 & 29975 & 148825 \\\\\n",
      "3 & 38 & 19 & 3 & 0 \\\\\n",
      "4 & 8 & 0 & 0 & 0 \\\\\n",
      "5 & 3 & 0 & 0 & 0 \\\\\n",
      "6 & 0 & 0 & 0 & 0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lookup_name(dataset_id):\n",
    "    try:\n",
    "        dataset_id = int(dataset_id)\n",
    "        return \"%s (%s)\" % (all_datasets[dataset_id][\"name\"].lower(), dataset_id)\n",
    "    except:\n",
    "        return dataset_id\n",
    "\n",
    "filtered_stuff = collections.defaultdict(lambda: collections.defaultdict(int))\n",
    "# This should maximally be set to 6, unless one has more than 64GB of RAM\n",
    "max_combinations = 6\n",
    "for i in range(2, max_combinations):\n",
    "    n_grams = collections.defaultdict(int)\n",
    "    used_where = collections.defaultdict(list)\n",
    "    for key, value in paper_to_datasets.groupby(\"Paper Key\"):\n",
    "        # Adding these back in takes an incredible amount of memory\n",
    "        if key in (\"gijsbers-arxiv22a\", \"bischl-neuripsdbt21a\"):\n",
    "            continue\n",
    "        dataset_ids = []\n",
    "        for _, row in value.iterrows():\n",
    "            if row[\"Invalid\"] == \"INVALID\":\n",
    "                name = row[\"Dataset Name\"]\n",
    "                dataset_ids.append(name)\n",
    "            elif row[\"Task Type\"] == \"Regression\":\n",
    "                continue\n",
    "            else:\n",
    "                dataset_id = row[\"Dataset ID\"]\n",
    "                dataset_mapping = row[\"Dataset Mapping\"]\n",
    "                if pd.isna(dataset_id) and pd.isna(dataset_mapping):\n",
    "                    raise ValueError(\"Both dataset ID fields are empty\", row)\n",
    "                elif not pd.isna(dataset_id) and not pd.isna(dataset_mapping):\n",
    "                    raise ValueError(\"Both dataset ID fields are populated\", row)\n",
    "                elif pd.isna(dataset_id):\n",
    "                    did = int(dataset_mapping)\n",
    "                else:\n",
    "                    did = int(dataset_id)\n",
    "                dataset_ids.append(did)\n",
    "        current_n_grams = list(itertools.combinations(dataset_ids, i))\n",
    "        # print(key, len(dataset_ids), len(current_n_grams))\n",
    "        for n_gram in current_n_grams:\n",
    "            n_gram = tuple(sorted([str(n) for n in n_gram]))\n",
    "            n_grams[n_gram] += 1\n",
    "            used_where[n_gram].append(key)\n",
    "\n",
    "    # now check how many dataset combinations we have per min appearance\n",
    "    for j in range(2, max_combinations + 1):\n",
    "        filtered = {key: value for key, value in n_grams.items() if value >= j}\n",
    "        filtered_list = sorted(list(filtered.items()), key=lambda t: t[1], reverse=True)\n",
    "        if len(filtered_list) > 0:\n",
    "            highest_value = filtered_list[0][1]\n",
    "            print(i, j, len(filtered_list), \", \".join([\"(\" + \", \".join([lookup_name(d) for d in fl[0]]) + \")\" for fl in filtered_list[:20] if fl[1] == highest_value]))\n",
    "        filtered_stuff[i][j] += len(filtered_list)\n",
    "\n",
    "print(pd.DataFrame(filtered_stuff).to_latex())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###\n",
      "agarwal-neurips21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "arik-aaai20a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "bahri-iclr22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "bischl-neuripsdbt21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "borisov-iclr23a\n",
      "###\n",
      "borisov-tnnls22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "buturovic-biorxiv20a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "cai-sigmod21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "chen-aaai22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "dubey-neurips22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "gijsbers-arxiv22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "gorishniy-neurips21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "gorishniy-neurips22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "grinsztajn-neuripsdbt22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "hollmann-iclr23a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "huang-arxiv20a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "joseph-arxiv22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "kadra-neurips21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "kossen-neurips21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "kotelnikov-openreview23a\n",
      "###\n",
      "levin-iclr23a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "popov-iclr20a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "radenovic-neurips22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "rubachev-openreview23a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "sarkar-isa22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "schaefl-openreview22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "shwartz-ziv-if22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "somepalli-openreview22a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "sun-cvprw19a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "yoon-neurips20a\n",
      "Classification okay\n",
      "Regression okay\n",
      "###\n",
      "zhu-sr21a\n",
      "Classification okay\n",
      "Regression okay\n",
      "(29, 7) (27, 7)\n",
      "                            Type          Method                             Paper  Classification  Regression  Invalid Classification  Other (according to paper)\n",
      "agarwal-neurips21a           New             NAM        \\citet{agarwal-neurips21a}        2.000000    2.000000                1.000000                    0.000000\n",
      "arik-aaai20a                 New          TabNet              \\citet{arik-aaai20a}        3.000000    2.000000                0.000000                    8.000000\n",
      "bahri-iclr22a                New           SCARF             \\citet{bahri-iclr22a}       69.000000    0.000000                0.000000                    0.000000\n",
      "borisov-iclr23a             Data           GReaT           \\citet{borisov-iclr23a}        0.000000    0.000000                0.000000                    6.000000\n",
      "borisov-tnnls22a            Comp               -          \\citet{borisov-tnnls22a}        4.000000    1.000000                0.000000                    0.000000\n",
      "buturovic-biorxiv20a         New             TAC      \\citet{buturovic-biorxiv20a}        1.000000    0.000000                1.000000                    0.000000\n",
      "cai-sigmod21a                New         ARM-Net             \\citet{cai-sigmod21a}        5.000000    0.000000                5.000000                    0.000000\n",
      "chen-aaai22a                 New           DANET              \\citet{chen-aaai22a}        4.000000    3.000000                1.000000                    0.000000\n",
      "dubey-neurips22a             New            SPAM          \\citet{dubey-neurips22a}        9.000000    4.000000                3.000000                    3.000000\n",
      "gorishniy-neurips21a        Comp  FT-Transformer      \\citet{gorishniy-neurips21a}        7.000000    4.000000                0.000000                    5.000000\n",
      "gorishniy-neurips22a         New        multiple      \\citet{gorishniy-neurips22a}        7.000000    4.000000                0.000000                    1.000000\n",
      "grinsztajn-neuripsdbt22a    Comp               -  \\citet{grinsztajn-neuripsdbt22a}       21.000000   35.000000                0.000000                    0.000000\n",
      "hollmann-iclr23a             New          TabPFN          \\citet{hollmann-iclr23a}       30.000000    0.000000                0.000000                  170.000000\n",
      "huang-arxiv20a               New  TabTransformer            \\citet{huang-arxiv20a}       20.000000    0.000000                1.000000                    0.000000\n",
      "joseph-arxiv22a              New            GATE           \\citet{joseph-arxiv22a}        3.000000    2.000000                0.000000                    0.000000\n",
      "kadra-neurips21a             New     RegCocktail          \\citet{kadra-neurips21a}       40.000000    0.000000                0.000000                    0.000000\n",
      "kossen-neurips21a            New             NPT         \\citet{kossen-neurips21a}        6.000000    4.000000                0.000000                    2.000000\n",
      "kotelnikov-openreview23a    Data               -  \\citet{kotelnikov-openreview23a}        0.000000    0.000000                0.000000                   16.000000\n",
      "levin-iclr23a                New        multiple             \\citet{levin-iclr23a}        1.000000    0.000000                1.000000                    2.000000\n",
      "popov-iclr20a                New            NODE             \\citet{popov-iclr20a}        3.000000    3.000000                1.000000                    0.000000\n",
      "radenovic-neurips22a         New             NBM      \\citet{radenovic-neurips22a}        8.000000    4.000000                3.000000                    3.000000\n",
      "rubachev-openreview23a       New        multiple    \\citet{rubachev-openreview23a}        6.000000    5.000000                0.000000                    1.000000\n",
      "sarkar-isa22a                New          XGBNet             \\citet{sarkar-isa22a}        8.000000    0.000000                2.000000                    0.000000\n",
      "schaefl-openreview22a        New         Hopular     \\citet{schaefl-openreview22a}       16.000000    0.000000                1.000000                    4.000000\n",
      "shwartz-ziv-if22a           Comp               -         \\citet{shwartz-ziv-if22a}        9.000000    2.000000                0.000000                    0.000000\n",
      "somepalli-openreview22a      New           SAINT   \\citet{somepalli-openreview22a}       20.000000   10.000000                0.000000                    1.000000\n",
      "sun-cvprw19a                 New        SuperTML              \\citet{sun-cvprw19a}        4.000000    0.000000                0.000000                    0.000000\n",
      "yoon-neurips20a              New            VIME           \\citet{yoon-neurips20a}       11.000000    0.000000                9.000000                    0.000000\n",
      "zhu-sr21a                    New            IGDT                 \\citet{zhu-sr21a}        0.000000    2.000000                0.000000                    0.000000\n",
      "Mean                        Mean                                                         11.740741    3.222222                1.074074                    7.407407\n",
      "Median                    Median                                                          7.000000    2.000000                0.000000                    0.000000\n",
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "Type & Method & Paper & Classification & Regression & Invalid Classification & Other (according to paper) \\\\\n",
      "\\midrule\n",
      "New & NAM & \\citet{agarwal-neurips21a} & 2 & 2 & 1 & 0 \\\\\n",
      "New & TabNet & \\citet{arik-aaai20a} & 3 & 2 & 0 & 8 \\\\\n",
      "New & SCARF & \\citet{bahri-iclr22a} & 69 & 0 & 0 & 0 \\\\\n",
      "Data & GReaT & \\citet{borisov-iclr23a} & 0 & 0 & 0 & 6 \\\\\n",
      "Comp & - & \\citet{borisov-tnnls22a} & 4 & 1 & 0 & 0 \\\\\n",
      "New & TAC & \\citet{buturovic-biorxiv20a} & 1 & 0 & 1 & 0 \\\\\n",
      "New & ARM-Net & \\citet{cai-sigmod21a} & 5 & 0 & 5 & 0 \\\\\n",
      "New & DANET & \\citet{chen-aaai22a} & 4 & 3 & 1 & 0 \\\\\n",
      "New & SPAM & \\citet{dubey-neurips22a} & 9 & 4 & 3 & 3 \\\\\n",
      "Comp & FT-Transformer & \\citet{gorishniy-neurips21a} & 7 & 4 & 0 & 5 \\\\\n",
      "New & multiple & \\citet{gorishniy-neurips22a} & 7 & 4 & 0 & 1 \\\\\n",
      "Comp & - & \\citet{grinsztajn-neuripsdbt22a} & 21 & 35 & 0 & 0 \\\\\n",
      "New & TabPFN & \\citet{hollmann-iclr23a} & 30 & 0 & 0 & 170 \\\\\n",
      "New & TabTransformer & \\citet{huang-arxiv20a} & 20 & 0 & 1 & 0 \\\\\n",
      "New & GATE & \\citet{joseph-arxiv22a} & 3 & 2 & 0 & 0 \\\\\n",
      "New & RegCocktail & \\citet{kadra-neurips21a} & 40 & 0 & 0 & 0 \\\\\n",
      "New & NPT & \\citet{kossen-neurips21a} & 6 & 4 & 0 & 2 \\\\\n",
      "Data & - & \\citet{kotelnikov-openreview23a} & 0 & 0 & 0 & 16 \\\\\n",
      "New & multiple & \\citet{levin-iclr23a} & 1 & 0 & 1 & 2 \\\\\n",
      "New & NODE & \\citet{popov-iclr20a} & 3 & 3 & 1 & 0 \\\\\n",
      "New & NBM & \\citet{radenovic-neurips22a} & 8 & 4 & 3 & 3 \\\\\n",
      "New & multiple & \\citet{rubachev-openreview23a} & 6 & 5 & 0 & 1 \\\\\n",
      "New & XGBNet & \\citet{sarkar-isa22a} & 8 & 0 & 2 & 0 \\\\\n",
      "New & Hopular & \\citet{schaefl-openreview22a} & 16 & 0 & 1 & 4 \\\\\n",
      "Comp & - & \\citet{shwartz-ziv-if22a} & 9 & 2 & 0 & 0 \\\\\n",
      "New & SAINT & \\citet{somepalli-openreview22a} & 20 & 10 & 0 & 1 \\\\\n",
      "New & SuperTML & \\citet{sun-cvprw19a} & 4 & 0 & 0 & 0 \\\\\n",
      "New & VIME & \\citet{yoon-neurips20a} & 11 & 0 & 9 & 0 \\\\\n",
      "New & IGDT & \\citet{zhu-sr21a} & 0 & 2 & 0 & 0 \\\\\n",
      "Mean &  &  & 11.740741 & 3.222222 & 1.074074 & 7.407407 \\\\\n",
      "Median &  &  & 7 & 2 & 0 & 0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Numbers from the paper\n",
    "suite_to_num_datasets = {\n",
    "    # Agarwal et al. uses Compas as a fifth dataset to demonstrate the intellegibility of the method. \n",
    "    # Also, it contains further datasets for multi-task learning, which we do not consider. \n",
    "    # Last but least, it incorrectly treat the FICO dataset as a regression dataset.\n",
    "    \"agarwal-neurips21a\":  (2, 2, 0, \"New\", \"NAM\"),\n",
    "    # Uses 6 synthetic datasets, 2 UCI datasets for interpretability as other, also does SSL on one of the main datasets. \n",
    "    # Uses 1 forecasting dataset which we count as regression in this list\n",
    "    \"arik-aaai20a\": (3, 2, 8, \"New\", \"TabNet\"),\n",
    "    # Uses 69 datasets from the CC18, drops MNIST, FASHION-MNIST and CIFAR10\n",
    "    \"bahri-iclr22a\": (69, 0, 0, \"New\", \"SCARF\"),\n",
    "    \"bischl-neuripsdbt21a\": (72, 0, 0, \"Suite\", None),\n",
    "    \"borisov-iclr23a\": (0, 0, 6, \"Data\", \"GReaT\"),\n",
    "    \"borisov-tnnls22a\": (4, 1, 0, \"Comp\", None),\n",
    "    # Use the adult dataset for interpretation and classification. Only counting it for classification.\n",
    "    \"buturovic-biorxiv20a\": (1, 0, 0, \"New\", \"TAC\"),\n",
    "    \"cai-sigmod21a\": (5, 0, 0, \"New\", \"ARM-Net\"),\n",
    "    \"chen-aaai22a\": (4, 3, 0, \"New\", \"DANET\"),\n",
    "    # Uses three image datasets as well\n",
    "    \"dubey-neurips22a\": (9, 4, 3, \"New\", \"SPAM\"),\n",
    "    \"gijsbers-arxiv22a\": (71, 0, 0, \"Suite\", None),\n",
    "    # 4 datasets that weren't interesting + 1 synthetic\n",
    "    \"gorishniy-neurips21a\": (7, 4, 5, \"Comp\", \"FT-Transformer\"),\n",
    "    # Same synthetic dataset as above\n",
    "    \"gorishniy-neurips22a\": (7, 4, 1, \"New\", \"multiple\"),\n",
    "    # Conduct further studies on dataset changes, not sure how relevant these are to mention\n",
    "    # The paper mentions 18 and 27 as distinct datasets, but the studies themselves\n",
    "    # have more papers because some datasets are transformed to purely numerical\n",
    "    \"grinsztajn-neuripsdbt22a\": (21, 18 + 17, 0, \"Comp\", None),\n",
    "    # Conduct generalization studies on 18 datasets, additional classification studies on 2 more datasets from the AutoML benchmark, and 150 validation datasets\n",
    "    \"hollmann-iclr23a\": (30, 0, 170, \"New\", \"TabPFN\"),\n",
    "    # One of the datasets is actually a multi-label dataset\n",
    "    \"huang-arxiv20a\": (20, 0, 0, \"New\", \"TabTransformer\"),\n",
    "    \"joseph-arxiv22a\": (3, 2, 0, \"New\", \"GATE\"),\n",
    "    \"kadra-neurips21a\": (40, 0, 0, \"New\", \"RegCocktail\"),\n",
    "    # That additional data is CIFAR-10\n",
    "    \"kossen-neurips21a\": (6, 4, 2, \"New\", \"NPT\"),\n",
    "    \"kotelnikov-openreview23a\": (0, 0, 16, \"Data\", None),\n",
    "    \"levin-iclr23a\": (1, 0, 2, \"New\", \"multiple\"),\n",
    "    \"popov-iclr20a\": (3, 3, 0, \"New\", \"NODE\"),\n",
    "    # Use three image datasets\n",
    "    \"radenovic-neurips22a\": (8, 4, 3, \"New\", \"NBM\"),\n",
    "    \"rubachev-openreview23a\": (6, 5, 1, \"New\", \"multiple\"),\n",
    "    \"sarkar-isa22a\": (8, 0, 0, \"New\", \"XGBNet\"),\n",
    "    # 16 small and 4 medium\n",
    "    \"schaefl-openreview22a\": (16, 0, 4, \"New\", \"Hopular\"),\n",
    "    # Also does ensembling of NNs and XGB, mistakes one regression dataset for a classification dataset\n",
    "    \"shwartz-ziv-if22a\": (9, 2, 0, \"Comp\", None),\n",
    "    # The additional dataset is MNIST used to interpret the attention mechanism\n",
    "    \"somepalli-openreview22a\": (20, 10, 1, \"New\", \"SAINT\"),\n",
    "    \"sun-cvprw19a\": (4, 0, 0, \"New\", \"SuperTML\"),\n",
    "    # 6 blood cells, 2 clinical data and 3 UCI\n",
    "    \"yoon-neurips20a\": (11, 0, 0, \"New\", \"VIME\"),\n",
    "    \"zhu-sr21a\": (0, 2, 0, \"New\", \"IGDT\"),\n",
    "}\n",
    "table_to_print = {}\n",
    "for suite in suite_to_num_datasets:\n",
    "\n",
    "    dataset_subset = paper_to_datasets[paper_to_datasets[\"Paper Key\"] == suite]\n",
    "    classification_subset = dataset_subset[dataset_subset[\"Task Type\"] == \"Classification\"]\n",
    "    classification_subset_dataset_ids = set()\n",
    "    for _, row in classification_subset.iterrows():\n",
    "        if not pd.isna(row[\"Dataset ID\"]) and not pd.isna(row[\"Dataset Mapping\"]):\n",
    "            raise ValueError(row)\n",
    "        elif not pd.isna(row[\"Dataset ID\"]):\n",
    "            classification_subset_dataset_ids.add(row[\"Dataset ID\"])\n",
    "        elif not pd.isna(row[\"Dataset Mapping\"]):\n",
    "            classification_subset_dataset_ids.add(row[\"Dataset Mapping\"])\n",
    "        elif row[\"Invalid\"] == \"INVALID\":\n",
    "            continue\n",
    "        else:\n",
    "            raise ValueError(row)\n",
    "        \n",
    "    #unused_classification_datasets = dataset_list_unused.query(\n",
    "    #    \"Reason in ['Private', 'Synthetic', 'OpenML', 'Unclear Format', 'String', 'Multilabel', 'Date', 'Unavailable', 'Too few classes', 'Proprietary']\"\n",
    "    #)\n",
    "    #unused_other_datasets = dataset_list_unused.query(\"Reason == 'Forcasting'\")\n",
    "    #assert len(unused_classification_datasets) + len(unused_other_datasets) == len(dataset_list_unused)\n",
    "    #if len(unused_other_datasets) > 0:\n",
    "    #    unused_classification_datasets = unused_classification_datasets.query(\"Dataset Name not in @unused_other_datasets\")\n",
    "    unused_classification_datasets = [dataset_name for dataset_name in dataset_list_unused[\"Dataset Name\"] if dataset_name in classification_subset.query(\"Invalid == 'INVALID'\")[\"Dataset Name\"].to_list()]\n",
    "    regression_subset = dataset_subset[dataset_subset[\"Task Type\"] == \"Regression\"]\n",
    "    other_subset = dataset_subset[dataset_subset[\"Invalid\"] == \"Invalid\"]\n",
    "\n",
    "    if suite in tabular_data_experiments.utils.suites.CUSTOM_SUITES:\n",
    "        dataset_ids_in_code = set([all_tasks[tid][\"did\"] for tid in tabular_data_experiments.utils.suites.CUSTOM_SUITES[suite]])\n",
    "    else:\n",
    "        dataset_ids_in_code = set()\n",
    "    dataset_ids_table = set(classification_subset_dataset_ids)\n",
    "    num_entries_in_code = len(dataset_ids_in_code)\n",
    "    num_entries_in_table = len(dataset_ids_table)\n",
    "    if num_entries_in_code != num_entries_in_table:\n",
    "        print(suite, num_entries_in_code, num_entries_in_table)\n",
    "        print(\"Entries in code\", dataset_ids_in_code)\n",
    "        print(\"Entries in google doc\", classification_subset_dataset_ids)\n",
    "        print(\"Entries missing from code\", dataset_ids_table - dataset_ids_in_code)\n",
    "        print(\"Entries missing from google doc\", dataset_ids_in_code - dataset_ids_table)\n",
    "\n",
    "    print(\"###\")\n",
    "    print(suite)\n",
    "    if suite_to_num_datasets[suite][3] != \"Data\":\n",
    "        if len(classification_subset_dataset_ids) + len(unused_classification_datasets) == suite_to_num_datasets[suite][0]:\n",
    "            print(\"Classification okay\")\n",
    "        else:\n",
    "            print(len(classification_subset_dataset_ids), len(unused_classification_datasets), suite_to_num_datasets[suite][0])\n",
    "        if regression_subset.shape[0] == suite_to_num_datasets[suite][1]:\n",
    "            print(\"Regression okay\")\n",
    "        else:\n",
    "            print(regression_subset.shape[0], suite_to_num_datasets[suite][1])\n",
    "\n",
    "    if suite_to_num_datasets[suite][3] == \"Suite\":\n",
    "        continue\n",
    "    elif suite_to_num_datasets[suite][3] == \"Data\":\n",
    "        table_to_print[suite] = {\n",
    "            \"Type\": suite_to_num_datasets[suite][3],\n",
    "            \"Method\": suite_to_num_datasets[suite][4] if suite_to_num_datasets[suite][4] else \"-\",\n",
    "            \"Paper\": \"\\\\citet{\" + suite + \"}\",\n",
    "            \"Classification\": 0,\n",
    "            \"Regression\": 0,\n",
    "            \"Invalid Classification\": 0,\n",
    "            \"Other (according to paper)\": suite_to_num_datasets[suite][2]\n",
    "        }\n",
    "    elif suite_to_num_datasets[suite][3] in (\"New\", \"Comp\"):\n",
    "        table_to_print[suite] = {\n",
    "            \"Type\": suite_to_num_datasets[suite][3],\n",
    "            \"Method\": suite_to_num_datasets[suite][4] if suite_to_num_datasets[suite][4] else \"-\",\n",
    "            \"Paper\": \"\\\\citet{\" + suite + \"}\",\n",
    "            \"Classification\": len(classification_subset),\n",
    "            \"Regression\": len(regression_subset),\n",
    "            \"Invalid Classification\": len(unused_classification_datasets),\n",
    "            \"Other (according to paper)\": suite_to_num_datasets[suite][2]\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(suite_to_num_datasets[suite][3])\n",
    "\n",
    "table_for_paper = pd.DataFrame(table_to_print).transpose()\n",
    "means = []\n",
    "medians = []\n",
    "table_for_paper_wo_data = table_for_paper[table_for_paper[\"Type\"] != \"Data\"]\n",
    "print(table_for_paper.shape, table_for_paper_wo_data.shape)\n",
    "for column in (\"Classification\", \"Regression\", \"Invalid Classification\", \"Other (according to paper)\"):\n",
    "    table_for_paper[column] = table_for_paper[column].astype(int)\n",
    "    means.append(table_for_paper_wo_data[column].mean())\n",
    "    medians.append(table_for_paper_wo_data[column].median())\n",
    "\n",
    "table_for_paper.loc[\"Mean\"] = [\"Mean\", \"\", \"\"] + means\n",
    "table_for_paper.loc[\"Median\"] = [\"Median\", \"\", \"\"] + medians\n",
    "print(table_for_paper)\n",
    "print(table_for_paper.to_latex(index=False).replace(\".000000\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "# This cell checks whether the paper introducing data generators feature any datasets not available in any other suites - and indeed, they do...\n",
    "pure_data_suites = set()\n",
    "for suite in suite_to_num_datasets:\n",
    "    if suite_to_num_datasets[suite][3] == \"Data\":\n",
    "        pure_data_suites = pure_data_suites | set(tabular_data_experiments.utils.suites.COLLECTION_KEYS)\n",
    "for suite in tabular_data_experiments.utils.suites.COLLECTION_KEYS:\n",
    "    if suite in (\"kotelnikov-openreview23a\", \"borisov-iclr23a\"):\n",
    "        continue\n",
    "    elif suite not in tabular_data_experiments.utils.suites.CUSTOM_SUITES:\n",
    "        print(suite)\n",
    "        continue\n",
    "    else:\n",
    "        pure_data_suites = pure_data_suites - set(tabular_data_experiments.utils.suites.COLLECTION_KEYS)\n",
    "print(pure_data_suites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huang-arxiv20a 361679 {'tid': 361679, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 45565, 'name': 'Adult-Census-Income', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '45565', 'target_feature': 'income', 'NumberOfFeatures': 15, 'NumberOfInstances': 32561, 'NumberOfInstancesWithMissingValues': 2399, 'NumberOfMissingValues': 4262, 'NumberOfNumericFeatures': 6, 'NumberOfSymbolicFeatures': 9}\n",
      "kossen-neurips21a 361634 {'tid': 361634, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 4535, 'name': 'Census-Income', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '4535', 'target_feature': 'V42', 'MaxNominalAttDistinctValues': 51, 'NumberOfFeatures': 42, 'NumberOfInstances': 299285, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 13, 'NumberOfSymbolicFeatures': 29}\n",
      "                          Numeric  Categorical  Mixed  Binary  Multiclass  Balancedness     Ratio\n",
      "agarwal-neurips21a            1.0          0.0    0.0     1.0         0.0      0.998273       inf\n",
      "arik-aaai20a                  2.0          0.0    1.0     1.0         2.0      0.506229  2.000000\n",
      "bahri-iclr22a                45.0          8.0   16.0    35.0        34.0      0.486523  1.875000\n",
      "bischl-neuripsdbt21a         48.0          8.0   16.0    35.0        37.0      0.470592  2.000000\n",
      "borisov-tnnls22a              1.0          0.0    3.0     3.0         1.0      0.574255  0.333333\n",
      "chen-aaai22a                  1.0          0.0    2.0     2.0         1.0      0.496114  0.500000\n",
      "dubey-neurips22a              3.0          0.0    3.0     5.0         1.0      0.594351  1.000000\n",
      "gijsbers-arxiv22a            42.0          6.0   23.0    41.0        30.0      0.559201  1.448276\n",
      "gorishniy-neurips21a          5.0          0.0    2.0     3.0         4.0      0.399975  2.500000\n",
      "gorishniy-neurips22a          4.0          0.0    3.0     3.0         4.0      0.539291  1.333333\n",
      "grinsztajn-neuripsdbt22a     14.0          0.0    7.0    21.0         0.0      0.500000  2.000000\n",
      "hollmann-iclr23a             19.0          3.0    8.0    17.0        13.0      0.523433  1.727273\n",
      "huang-arxiv20a                8.0          1.0   10.0    13.0         5.0      0.620891  0.727273\n",
      "joseph-arxiv22a               1.0          0.0    2.0     1.0         2.0      0.493800  0.500000\n",
      "kadra-neurips21a             27.0          3.0   10.0    19.0        21.0      0.491699  2.076923\n",
      "kossen-neurips21a             2.0          1.0    3.0     3.0         2.0      0.619699  0.500000\n",
      "popov-iclr20a                 2.0          0.0    0.0     2.0         0.0      0.515182       inf\n",
      "radenovic-neurips22a          3.0          0.0    2.0     4.0         1.0      0.607310  1.500000\n",
      "rubachev-openreview23a        3.0          0.0    3.0     2.0         4.0      0.467247  1.000000\n",
      "sarkar-isa22a                 4.0          1.0    1.0     3.0         3.0      0.481305  2.000000\n",
      "schaefl-openreview22a         6.0          3.0    6.0    12.0         3.0      0.567475  0.666667\n",
      "shwartz-ziv-if22a             5.0          0.0    4.0     3.0         6.0      0.479425  1.250000\n",
      "somepalli-openreview22a       7.0          3.0   10.0    10.0        10.0      0.605498  0.538462\n",
      "sun-cvprw19a                  3.0          0.0    1.0     2.0         2.0      0.537802  3.000000\n",
      "yoon-neurips20a               1.0          0.0    1.0     1.0         1.0      0.436623  1.000000\n",
      "Numeric         10.280000\n",
      "Categorical      1.480000\n",
      "Mixed            5.480000\n",
      "Binary           9.680000\n",
      "Multiclass       7.480000\n",
      "Balancedness     0.542888\n",
      "Ratio                 inf\n",
      "dtype: float64\n",
      "Numeric         4.000000\n",
      "Categorical     0.000000\n",
      "Mixed           3.000000\n",
      "Binary          3.000000\n",
      "Multiclass      3.000000\n",
      "Balancedness    0.515182\n",
      "Ratio           1.448276\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# This cell further describes the suites in terms of the number of categorical and numerical datasets\n",
    "suite_statistics = {}\n",
    "for suite in suite_to_num_datasets:\n",
    "    n_numeric_datasets = 0\n",
    "    n_mixed_datests = 0\n",
    "    n_categorical_datasets = 0\n",
    "    n_binary = 0\n",
    "    n_multiclass = 0\n",
    "    balancedness = []\n",
    "    if suite not in tabular_data_experiments.utils.suites.CUSTOM_SUITES:\n",
    "        continue\n",
    "    elif suite_to_num_datasets[suite][3] == \"Data\":\n",
    "        continue\n",
    "    for task_id in tabular_data_experiments.utils.suites.CUSTOM_SUITES[suite]:\n",
    "        n_symbolic = all_tasks[task_id]['NumberOfSymbolicFeatures']\n",
    "        n_numeric = all_tasks[task_id]['NumberOfNumericFeatures']\n",
    "        if n_symbolic == 1:\n",
    "            n_numeric_datasets += 1\n",
    "        elif n_numeric == 0:\n",
    "            n_categorical_datasets += 1\n",
    "        else:\n",
    "            n_mixed_datests += 1\n",
    "        try:\n",
    "            if all_tasks[task_id][\"NumberOfClasses\"] == 2:\n",
    "                n_binary += 1\n",
    "            else: \n",
    "                n_multiclass += 1\n",
    "        except KeyError:\n",
    "            print(suite, task_id, all_tasks[task_id], flush=True)\n",
    "            pass\n",
    "        try:\n",
    "            balancedness.append(all_tasks[task_id][\"MajorityClassSize\"] / all_tasks[task_id][\"NumberOfInstances\"])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    suite_statistics[suite] = {\n",
    "        'Numeric': n_numeric_datasets, \n",
    "        \"Categorical\": n_categorical_datasets, \n",
    "        \"Mixed\": n_mixed_datests,\n",
    "        \"Binary\": n_binary,\n",
    "        \"Multiclass\": n_multiclass, \n",
    "        \"Balancedness\": np.mean(balancedness)   \n",
    "    }\n",
    "\n",
    "suite_statistics = pd.DataFrame(suite_statistics).transpose()\n",
    "suite_statistics[\"Ratio\"] = suite_statistics[\"Numeric\"] / (suite_statistics[\"Categorical\"] + suite_statistics[\"Mixed\"])\n",
    "print(suite_statistics)\n",
    "print(suite_statistics.mean())\n",
    "print(suite_statistics.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tid': 361500, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 151, 'name': 'electricity', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '151', 'target_feature': 'class', 'MajorityClassSize': 26075, 'MaxNominalAttDistinctValues': 7, 'MinorityClassSize': 19237, 'NumberOfClasses': 2, 'NumberOfFeatures': 9, 'NumberOfInstances': 45312, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 7, 'NumberOfSymbolicFeatures': 2}\n",
      "{'tid': 361516, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 4134, 'name': 'Bioresponse', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '4134', 'target_feature': 'target', 'MajorityClassSize': 2034, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 1717, 'NumberOfClasses': 2, 'NumberOfFeatures': 1777, 'NumberOfInstances': 3751, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 1776, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361532, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 1461, 'name': 'bank-marketing', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '1461', 'target_feature': 'Class', 'MajorityClassSize': 39922, 'MaxNominalAttDistinctValues': 12, 'MinorityClassSize': 5289, 'NumberOfClasses': 2, 'NumberOfFeatures': 17, 'NumberOfInstances': 45211, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 7, 'NumberOfSymbolicFeatures': 10}\n",
      "{'tid': 361555, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 1596, 'name': 'covertype', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '1596', 'target_feature': 'class', 'MajorityClassSize': 283301, 'MaxNominalAttDistinctValues': 7, 'MinorityClassSize': 2747, 'NumberOfClasses': 7, 'NumberOfFeatures': 55, 'NumberOfInstances': 581012, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 10, 'NumberOfSymbolicFeatures': 45}\n",
      "{'tid': 361564, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 41147, 'name': 'albert', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '41147', 'target_feature': 'class', 'MajorityClassSize': 212620, 'MinorityClassSize': 212620, 'NumberOfClasses': 2, 'NumberOfFeatures': 79, 'NumberOfInstances': 425240, 'NumberOfInstancesWithMissingValues': 425159, 'NumberOfMissingValues': 2734000, 'NumberOfNumericFeatures': 26, 'NumberOfSymbolicFeatures': 53}\n",
      "{'tid': 361570, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 41168, 'name': 'jannis', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '41168', 'target_feature': 'class', 'MajorityClassSize': 38522, 'MaxNominalAttDistinctValues': 4, 'MinorityClassSize': 1687, 'NumberOfClasses': 4, 'NumberOfFeatures': 55, 'NumberOfInstances': 83733, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 54, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361571, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 4541, 'name': 'Diabetes130US', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '4541', 'target_feature': 'readmitted', 'MajorityClassSize': 54864, 'MaxNominalAttDistinctValues': 790, 'MinorityClassSize': 11357, 'NumberOfClasses': 3, 'NumberOfFeatures': 50, 'NumberOfInstances': 101766, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 13, 'NumberOfSymbolicFeatures': 37}\n",
      "{'tid': 361584, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 41150, 'name': 'MiniBooNE', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '41150', 'target_feature': 'signal', 'MajorityClassSize': 93565, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 36499, 'NumberOfClasses': 2, 'NumberOfFeatures': 51, 'NumberOfInstances': 130064, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 50, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361639, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 42477, 'name': 'default-of-credit-card-clients', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '42477', 'target_feature': 'y', 'MajorityClassSize': 23364, 'MinorityClassSize': 6636, 'NumberOfClasses': 2, 'NumberOfFeatures': 24, 'NumberOfInstances': 30000, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 23, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361591, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 42769, 'name': 'Higgs', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '42769', 'target_feature': 'target', 'MajorityClassSize': 529920, 'MinorityClassSize': 470080, 'NumberOfClasses': 2, 'NumberOfFeatures': 29, 'NumberOfInstances': 1000000, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 28, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361639, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 42477, 'name': 'default-of-credit-card-clients', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '42477', 'target_feature': 'y', 'MajorityClassSize': 23364, 'MinorityClassSize': 6636, 'NumberOfClasses': 2, 'NumberOfFeatures': 24, 'NumberOfInstances': 30000, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 23, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361656, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 1044, 'name': 'eye_movements', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '1044', 'target_feature': 'label', 'MajorityClassSize': 4262, 'MaxNominalAttDistinctValues': 3, 'MinorityClassSize': 2870, 'NumberOfClasses': 3, 'NumberOfFeatures': 28, 'NumberOfInstances': 10936, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 24, 'NumberOfSymbolicFeatures': 4}\n",
      "{'tid': 361683, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 293, 'name': 'covertype', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '293', 'target_feature': 'Y', 'MajorityClassSize': 297711, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 283301, 'NumberOfClasses': 2, 'NumberOfFeatures': 55, 'NumberOfInstances': 581012, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 54, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361684, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 722, 'name': 'pol', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '722', 'target_feature': 'binaryClass', 'MajorityClassSize': 9959, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 5041, 'NumberOfClasses': 2, 'NumberOfFeatures': 49, 'NumberOfInstances': 15000, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 48, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361685, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 821, 'name': 'house_16H', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '821', 'target_feature': 'binaryClass', 'MajorityClassSize': 16040, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 6744, 'NumberOfClasses': 2, 'NumberOfFeatures': 17, 'NumberOfInstances': 22784, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 16, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361686, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 1120, 'name': 'MagicTelescope', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '1120', 'target_feature': 'class:', 'MajorityClassSize': 12332, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 6688, 'NumberOfClasses': 2, 'NumberOfFeatures': 12, 'NumberOfInstances': 19020, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 11, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361687, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 42192, 'name': 'compas-two-years', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '42192', 'target_feature': 'two_year_recid', 'MajorityClassSize': 2795, 'MaxNominalAttDistinctValues': 2, 'MinorityClassSize': 2483, 'NumberOfClasses': 2, 'NumberOfFeatures': 14, 'NumberOfInstances': 5278, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 7, 'NumberOfSymbolicFeatures': 7}\n",
      "{'tid': 361689, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 45577, 'name': 'Give-Me-Some-Credit', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '45577', 'target_feature': 'SeriousDlqin2yrs', 'MajorityClassSize': 139974, 'MinorityClassSize': 10026, 'NumberOfClasses': 2, 'NumberOfFeatures': 11, 'NumberOfInstances': 150000, 'NumberOfInstancesWithMissingValues': 29731, 'NumberOfMissingValues': 33655, 'NumberOfNumericFeatures': 10, 'NumberOfSymbolicFeatures': 1}\n",
      "{'tid': 361690, 'ttid': <TaskType.SUPERVISED_CLASSIFICATION: 1>, 'did': 45578, 'name': 'California-Housing-Classification', 'task_type': 'Supervised Classification', 'status': 'active', 'estimation_procedure': '4-fold Crossvalidation', 'source_data': '45578', 'target_feature': 'medianHouseValue', 'MajorityClassSize': 10323, 'MinorityClassSize': 10317, 'NumberOfClasses': 2, 'NumberOfFeatures': 9, 'NumberOfInstances': 20640, 'NumberOfInstancesWithMissingValues': 0, 'NumberOfMissingValues': 0, 'NumberOfNumericFeatures': 8, 'NumberOfSymbolicFeatures': 1}\n"
     ]
    }
   ],
   "source": [
    "for task_id in tabular_data_experiments.utils.suites.CUSTOM_SUITES[\"grinsztajn-neuripsdbt22a_unpreprocessed\"]:\n",
    "    print(all_tasks[task_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
